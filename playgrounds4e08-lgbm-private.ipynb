{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"},{"sourceId":190672036,"sourceType":"kernelVersion"},{"sourceId":191018477,"sourceType":"kernelVersion"},{"sourceId":191020336,"sourceType":"kernelVersion"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IMPORTS AND INSTALLATIONS**","metadata":{}},{"cell_type":"code","source":"%%capture \n\n!cp /kaggle/usr/lib/regularimports/playgrounds4e08_regularimports.py myimports.py\nfrom myimports import *\n\nclear_output();","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **FOREWORD**","metadata":{}},{"cell_type":"markdown","source":"This is my private work for the competition. <br>\nI shall extract the original data separately and add this in full to each fold in the training data","metadata":{}},{"cell_type":"markdown","source":"# **CONFIGURATION**","metadata":{}},{"cell_type":"code","source":"%%time \n\ntarget      = \"class\"\ntest_req    = False\n\nmodel_label = \"LGBM\"\nversion_nb  = 2\nmodel_group = 1\ndevice      = \"cpu\"\n\nop_path    = f\"/kaggle/working\"\nip_path    = f\"/kaggle/input/playgrounds4e08-datastore\"\n\norig_req   = True\nnsamples   = 1.0\n\nn_splits     = 5\nstate        = 42\nftre_imp_req = True\ncutoff       = 0.50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **DATA LOADS**","metadata":{}},{"cell_type":"code","source":"%%time \n\nPrintColor(f\"---> Loading datasets\")\nX        = pd.read_parquet(os.path.join(ip_path, \"train.parquet\"))\ntest     = pd.read_parquet(os.path.join(ip_path, \"test.parquet\"))\nsub_fl   = pd.read_parquet(os.path.join(ip_path, \"sample_submission.parquet\"))\n\ncat_cols = \\\n['capshape', 'capsurface', 'capcolor', 'doesbruiseorbleed',\n 'gillattachment', 'gillspacing', 'gillcolor', 'stemroot', 'stemsurface',\n 'stemcolor', 'veiltype', 'veilcolor', 'hasring', 'ringtype',\n 'sporeprintcolor', 'habitat', 'season'\n ]\n\nX[cat_cols]     = X[cat_cols].astype(\"category\")\ntest[cat_cols]  = test[cat_cols].astype(\"category\")\n\nPrintColor(f\"---> Shapes = {X.shape} | {test.shape}\", color = Fore.CYAN)\n\nPrintColor(f\"---> Separating original data\")\nif orig_req:\n    PrintColor(f\"\\n---> We need the original data for model training\")\n    \n    if isinstance(nsamples, int):\n        PrintColor(f\"---> Partial original data is used = {nsamples:,.0f}\", color = Fore.CYAN) \n        \n        original = X.loc[X.Source == 'Original'].groupby(target).sample(n = nsamples)\n        X = X.loc[X.Source == 'Competition']\n        X.index = range(len(X))\n        original.index = range(len(original))\n        \n    elif nsamples == 1.0:\n        PrintColor(f\"---> Full original data is used\", color = Fore.CYAN) \n        original = X.loc[X.Source == 'Original']\n        original.index = range(len(original))\n        X = X.loc[X.Source == 'Competition']\n        X.index = range(len(X))\n        \nelse:\n    X = X.loc[X.Source == 'Competition']\n    PrintColor(f\"---> Shapes = {X.shape} | {test.shape} | without original data\", \n               color = Fore.RED\n              )\n\n# Sampling for testing purposes\nif test_req:\n    \n    X       = X.groupby(target).head(1000)\n    X.index = range(len(X))\n    test    = test.iloc[0:100]\n    sub_fl  = sub_fl.iloc[0:100]\n    \n    original = original.groupby(target).head(1000)\n    original.index = range(len(original))\n    \n    PrintColor(f\"---> Shapes = {X.shape} | {test.shape} | {original.shape} | Syntax check\", \n               color = Fore.RED\n              )\nelse:\n    PrintColor(f\"---> Syntax check is not needed\", color = Fore.RED)\n    \ny = X[target].astype(np.uint8)\nX = X.drop(target, axis=1)\n\nPrintColor(f\"---> Shapes = {X.shape} | {y.shape} | {test.shape} | {original.shape}\")\n    \nprint();\ncollect();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODEL TRAINING**","metadata":{}},{"cell_type":"code","source":"%%time \n\ncv         = SKF(n_splits= n_splits, shuffle= True, random_state = state)\nscores1    = []\nscores2    = []\ndrop_cols  = [\"Source\", \"id\", target]\nftre_imp   = 0\nsel_cols   = X.drop(columns = drop_cols, errors = \"ignore\").columns\n\ntest_preds = 0\norig_preds = 0\nOOF_Preds = pd.DataFrame(X.loc[X.Source == 'Competition'].index, \n                         columns = [f\"{model_label}V{version_nb}_{model_group}\"],\n                         dtype = np.float32,\n                        )\n\nPrintColor(f\"\\n-------- {model_label} MODEL TRAINING --------\\n\")\nfor fold_nb, (train_idx, dev_idx) in tqdm(enumerate(cv.split(X, y))):\n    \n    PrintColor(f\" {'-' * 15} Fold {fold_nb} {'-' * 15} \", \n               color = Fore.RED\n              )\n\n    Xtr  = X.iloc[train_idx][sel_cols]\n    ytr  = y.iloc[train_idx]\n    Xdev = X.iloc[dev_idx].query(\"Source == 'Competition'\")[sel_cols]\n    ydev = y.loc[Xdev.index]\n    \n    print(f\"---> {Xtr.shape} {ytr.shape} | without original\")\n    \n    if orig_req:\n        Xtr = pd.concat([Xtr, original[sel_cols]], axis=0, ignore_index = True)\n        ytr = pd.concat([ytr, original[target]], axis=0, ignore_index = True)\n        print(f\"---> {Xtr.shape} {ytr.shape} | with original\")\n            \n    model = LGBMC(objective     = \"binary\",\n                  eval_metric   = \"logloss\",\n                  device        = device,\n                  n_estimators  = 3000,\n                  max_depth     = 9,\n                  learning_rate = 0.06, \n                  random_state  = state,\n                  max_bin       = 1024,\n                  colsample_bytree = 0.7,\n                  reg_lambda    = 80,\n                  verbosity     = -1,\n                 )\n\n    model.fit(Xtr, ytr,\n              eval_set  = [(Xdev, ydev)],\n              eval_names = [(\"Dev\")],\n              callbacks = [log_evaluation(0), early_stopping(100)],\n              )\n\n    if ftre_imp_req:\n        ftre_imp  = ftre_imp + model.feature_importances_\n\n    score1    = model.best_score_['Dev']['binary_logloss']\n    dev_preds = model.predict_proba(Xdev)[:,1]\n    score2    = matthews_corrcoef(ydev, np.where(dev_preds >= cutoff, 1, 0))\n\n    print(f\"---> OOF score [Logloss | MCC] = {score1:.6f} | {score2 :.6f}\")\n    scores1.append(score1)\n    scores2.append(score2)\n\n    test_preds = test_preds + (model.predict_proba(test[sel_cols])[:, 1] / n_splits)                          \n    OOF_Preds.loc[Xdev.index, f\"{model_label}V{version_nb}_{model_group}\"] = dev_preds\n    \n    if orig_req:\n        orig_preds = orig_preds + (model.predict_proba(original[sel_cols])[:,1]/ n_splits)\n        \n    \n    del Xtr, Xdev, ytr, ydev, score1, score2, model;\n    collect();\n    print(f\"\\n{'=' * 50}\\n\")\n\nPrintColor(f'\\n\\n---> {np.mean(scores1) :.6f} +- {np.std(scores1) :.6f} | OOF model eval metric score',\n          color = Fore.CYAN\n          )\nPrintColor(f'---> {np.mean(scores2) :.6f} +- {np.std(scores2) :.6f} | OOF assignment metric score',\n          color = Fore.CYAN\n          )\n\ncollect();\nprint();\n\nif ftre_imp_req:\n    display(pd.DataFrame(ftre_imp, index = sel_cols, columns = [\"FtreImp\"]).\\\n            sort_values([\"FtreImp\"], ascending = False).\\\n            transpose().\\\n            style.format(formatter = \"{:,.2f}\").\\\n            set_caption(f\"Feature Importances\").\\\n            set_properties(**{\"text-align\": \"center\"}).\\\n            background_gradient(subset = sel_cols,\n                                cmap = \"rocket\", \n                                axis=1\n                               )\n            )\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CLOSURE**","metadata":{}},{"cell_type":"code","source":"def PostProcessPreds(sub_fl: pd.DataFrame, target: str = target):\n    \"This function post-processes the predictions using saved predictions and targets\"\n    \n    try:\n        sub_fl = sub_fl.set_index(\"id\")\n    except:\n        print(f\"---> Submission file index is intact\")\n\n    sub_fl.loc[3640058, target] = \"e\"\n    sub_fl.loc[sub_fl.index.isin([3600675, 4057201, 4729429, 4929268, 4985595]), target] = \"p\"\n    return sub_fl;","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nprint(\"\\n\\n\")\nsub_fl[target] = np.where(test_preds >= cutoff, \"p\", \"e\")\nsub_fl = PostProcessPreds(sub_fl)\n\ntest_preds = \\\npd.DataFrame(test_preds,index = range(len(test)),\n             columns = [f\"{model_label}V{version_nb}_{model_group}\"],\n             dtype = np.float32,\n            )\n\nprint(\"\\n\\n\")\ndisplay(test_preds.head(10).style.set_caption(f\"Submission file predictions\"))\nprint(\"\\n\\n\")\ndisplay(sub_fl.head(10).style.set_caption(f\"Submission file labels\"))\nprint(\"\\n\\n\")\n\nOOF_Preds.index.name = \"id\"\nOOF_Preds.sort_index().reset_index().\\\nto_parquet(os.path.join(op_path, f'OOF_Preds_{model_label}V{version_nb}_{model_group}.parquet'))\n\ntest_preds.\\\nto_parquet(os.path.join(op_path, f'Mdl_Preds_{model_label}V{version_nb}_{model_group}.parquet'))\n\nsub_fl.\\\nto_csv(os.path.join(op_path, f'Submission_{model_label}V{version_nb}_{model_group}.csv'),\n       index= True\n      )\n\nif orig_req:\n    pd.DataFrame(orig_preds, \n                 columns = [f\"{model_label}V{version_nb}_{model_group}\"], \n                 index = range(len(original)),\n                 dtype = np.float32,\n                ).\\\n    to_parquet(os.path.join(op_path, f'Orig_Preds_{model_label}V{version_nb}_{model_group}.parquet'))\n\nprint()\n!ls\n%reset -f","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CHECKS**","metadata":{}},{"cell_type":"code","source":"%%time\n\nimport pandas as pd\n\ndisplay(\n    pd.read_parquet(\"Orig_Preds_LGBMV2_1.parquet\").\\\n    head(10).style.format(precision = 5).\\\n    set_caption(\"Original data predictions\")\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}