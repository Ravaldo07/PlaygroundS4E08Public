{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76727,"databundleVersionId":9045607,"sourceType":"competition"},{"sourceId":190672036,"sourceType":"kernelVersion"},{"sourceId":191018477,"sourceType":"kernelVersion"},{"sourceId":191020336,"sourceType":"kernelVersion"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IMPORTS AND INSTALLATIONS**","metadata":{}},{"cell_type":"code","source":"%%capture \n\n!cp /kaggle/usr/lib/regularimports/playgrounds4e08_regularimports.py myimports.py\nfrom myimports import *","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-08-03T15:07:53.844911Z","iopub.execute_input":"2024-08-03T15:07:53.845298Z","iopub.status.idle":"2024-08-03T15:08:50.156999Z","shell.execute_reply.started":"2024-08-03T15:07:53.845264Z","shell.execute_reply":"2024-08-03T15:08:50.155661Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting lightgbm==4.5.0\n  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\nRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from lightgbm==4.5.0) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm==4.5.0) (1.11.4)\nDownloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lightgbm\n  Attempting uninstall: lightgbm\n    Found existing installation: lightgbm 4.2.0\n    Uninstalling lightgbm-4.2.0:\n      Successfully uninstalled lightgbm-4.2.0\nSuccessfully installed lightgbm-4.5.0\nCollecting polars==1.2.1\n  Downloading polars-1.2.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\nDownloading polars-1.2.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.9/30.9 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: polars\n  Attempting uninstall: polars\n    Found existing installation: polars 1.1.0\n    Uninstalling polars-1.1.0:\n      Successfully uninstalled polars-1.1.0\nSuccessfully installed polars-1.2.1\nCollecting ucimlrepo\n  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ucimlrepo) (2.2.2)\nRequirement already satisfied: certifi>=2020.12.5 in /opt/conda/lib/python3.10/site-packages (from ucimlrepo) (2024.7.4)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\nDownloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\nInstalling collected packages: ucimlrepo\nSuccessfully installed ucimlrepo-0.0.7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **FOREWORD**","metadata":{}},{"cell_type":"markdown","source":"This kernel starts with the datasets created in the [Data-Store](https://www.kaggle.com/code/ravi20076/playgrounds4e08-datastore) kernel. I do this to prevent multiple data creation endeavors across my experiments as I move along my model pipeline. <br>\n\nIn this kernel, we start off with a simple LightGBM baseline model and assess the efficiacy of adding the tertiary original data to the model data. <br>\nNote that the tertiary data is created from the associated GitHub repository but it does not have the GAN-noise component in the competition dataset. We need to factor this in our model endeavors in this assignment. ","metadata":{}},{"cell_type":"markdown","source":"# **CONFIGURATION**","metadata":{}},{"cell_type":"code","source":"%%time \n\ntarget      = \"class\"\ntest_req    = False\n\nmodel_label = \"LGBM\"\nversion_nb  = 1\nmodel_group = 6\ndevice      = \"cpu\"\n\nop_path    = f\"/kaggle/working\"\nip_path    = f\"/kaggle/input/playgrounds4e08-datastore\"\n\norig_req   = True\nnsamples   = 10_000\n\nn_splits     = 5\nstate        = 42\nftre_imp_req = True\ncutoff       = 0.50","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:11:17.565720Z","iopub.execute_input":"2024-08-03T15:11:17.566373Z","iopub.status.idle":"2024-08-03T15:11:17.575767Z","shell.execute_reply.started":"2024-08-03T15:11:17.566319Z","shell.execute_reply":"2024-08-03T15:11:17.574027Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"CPU times: user 6 µs, sys: 1 µs, total: 7 µs\nWall time: 11.9 µs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **DATA LOADS**","metadata":{}},{"cell_type":"code","source":"%%time \n\nX      = pd.read_parquet(os.path.join(ip_path, \"train.parquet\"))\ntest   = pd.read_parquet(os.path.join(ip_path, \"test.parquet\"))\nsub_fl = pd.read_parquet(os.path.join(ip_path, \"sample_submission.parquet\"))\n\ncat_cols = \\\n['capshape', 'capsurface', 'capcolor', 'doesbruiseorbleed',\n 'gillattachment', 'gillspacing', 'gillcolor', 'stemroot', 'stemsurface',\n 'stemcolor', 'veiltype', 'veilcolor', 'hasring', 'ringtype',\n 'sporeprintcolor', 'habitat', 'season'\n ]\n\nX[cat_cols]     = X[cat_cols].astype(\"category\")\ntest[cat_cols]  = test[cat_cols].astype(\"category\")\n\nPrintColor(f\"---> Shapes = {X.shape} | {test.shape}\")\n\nif orig_req:\n    PrintColor(f\"\\n---> We need the original data for model training\")\n    \n    if isinstance(nsamples, int):\n        original = X.loc[X.Source == 'Original'].groupby(target).sample(n = nsamples)\n        X = X.loc[X.Source == 'Competition']\n        X = pd.concat([X, original], axis=0, ignore_index = True)\n        X.index = range(len(X))\n        del original\n        \n    elif nsamples == 1.0:\n        PrintColor(f\"---> Full original data is used\")     \nelse:\n    X = X.loc[X.Source == 'Competition']\n    PrintColor(f\"---> Shapes = {X.shape} | {test.shape} | without original data\", \n               color = Fore.RED\n              )\n\n# Sampling for testing purposes\nif test_req:\n    X       = X.groupby([target, \"Source\"]).head(1000)\n    X.index = range(len(X))\n    test    = test.iloc[0:100]\n    sub_fl  = sub_fl.iloc[0:100]\n    \n    PrintColor(f\"---> Shapes = {X.shape} | {test.shape}\")\nelse:\n    PrintColor(f\"---> Syntax check is not needed\", color = Fore.RED)\n    \ny = X[target]\nX = X.drop(target, axis=1)\n\nPrintColor(f\"---> Shapes = {X.shape} | {y.shape} | {test.shape}\")\n    \nprint();\ncollect();","metadata":{"execution":{"iopub.status.busy":"2024-08-03T15:11:20.363847Z","iopub.execute_input":"2024-08-03T15:11:20.364869Z","iopub.status.idle":"2024-08-03T15:11:40.613688Z","shell.execute_reply.started":"2024-08-03T15:11:20.364826Z","shell.execute_reply":"2024-08-03T15:11:40.612172Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"\u001b[1m\u001b[34m---> Shapes = (4201981, 22) | (2077964, 21)\u001b[0m\n\u001b[1m\u001b[34m\n---> We need the original data for model training\u001b[0m\n\u001b[1m\u001b[31m---> Syntax check is not needed\u001b[0m\n\u001b[1m\u001b[34m---> Shapes = (3216945, 21) | (3216945,) | (2077964, 21)\u001b[0m\n\nCPU times: user 21.2 s, sys: 2.96 s, total: 24.1 s\nWall time: 20.2 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **MODEL TRAINING**","metadata":{}},{"cell_type":"markdown","source":"|Version Label| Kernel version | Model| Description| OOF CV score| LB score|\n|:-:| :-: | :-:| --------| :-:| :-:|\n|1  | 2    | LGBM | * Excluded original data completely |0.984660 +- 0.000028 | | \n|2  | 3    | LGBM | * Included 100_000 grouped original data samples |0.984635 +- 0.000163  | |\n|3  | 4    | LGBM | * Included complete original data samples |0.984675 +- 0.000141 | |\n|4  | 5    | LGBM | * Included 250_000 grouped original data samples |0.984656 +- 0.000411  | |\n|5  | 8    | LGBM | * Included 50_000 grouped original data samples |0.984661 +- 0.000131 | |","metadata":{}},{"cell_type":"code","source":"%%time \n\ncv         = SKF(n_splits= n_splits, shuffle= True, random_state = state)\ntest_preds = 0\nscores     = []\ndrop_cols  = [\"Source\", \"id\", target]\nftre_imp   = 0\nsel_cols   = X.drop(columns = drop_cols, errors = \"ignore\").columns\n\nOOF_Preds = pd.DataFrame(X.loc[X.Source == 'Competition'].index, \n                         columns = [f\"{model_label}V{version_nb}_{model_group}\"],\n                         dtype = np.float32,\n                        )\n\nPrintColor(f\"\\n-------- {model_label} MODEL TRAINING --------\\n\")\nfor fold_nb, (train_idx, dev_idx) in tqdm(enumerate(cv.split(X, y))):\n\n    Xtr  = X.iloc[train_idx][sel_cols]\n    ytr  = y.iloc[train_idx]\n    Xdev = X.iloc[dev_idx].query(\"Source == 'Competition'\")[sel_cols]\n    ydev = y.loc[Xdev.index]\n    \n    model = LGBMC(objective     = \"binary\",\n                  eval_metric   = \"logloss\",\n                  device        = device,\n                  n_estimators  = 3000,\n                  max_depth     = 9,\n                  learning_rate = 0.06, \n                  random_state  = state,\n                  max_bin       = 1024,\n                  colsample_bytree = 0.7,\n                  reg_lambda    = 80,\n                  verbosity     = -1,\n                 )\n\n    model.fit(Xtr, ytr,\n              eval_set  = [(Xdev, ydev)],\n              eval_names = [(\"Dev\")],\n              callbacks = [log_evaluation(0), early_stopping(100)],\n              )\n\n    if ftre_imp_req:\n        ftre_imp  = ftre_imp + model.feature_importances_\n\n    score1    = model.best_score_['Dev']['binary_logloss']\n    dev_preds = model.predict_proba(Xdev)[:,1]\n    score2    = matthews_corrcoef(ydev, np.where(dev_preds >= cutoff, 1, 0))\n\n    print(f\"---> OOF score [Logloss | MCC] = {score1:.6f} | {score2 :.6f} | Fold{fold_nb}\")\n    scores.append(score2)\n\n    test_preds = test_preds + (model.predict_proba(test[sel_cols])[:, 1]/n_splits)                          \n    OOF_Preds.loc[Xdev.index, f\"{model_label}V{version_nb}_{model_group}\"] = dev_preds;\n    del Xtr, Xdev, ytr, ydev, score1, score2, model;\n    collect();\n\nPrintColor(f'\\n\\n---> OOF MCC score: {np.mean(scores) :.6f} +- {np.std(scores) :.6f} \\n',\n          color = Fore.CYAN\n          )\ncollect();\nprint();\n\nif ftre_imp_req:\n    display(pd.DataFrame(ftre_imp, index = sel_cols, columns = [\"FtreImp\"]).\\\n            sort_values([\"FtreImp\"], ascending = False).\\\n            transpose().\\\n            style.format(formatter = \"{:,.2f}\").\\\n            set_caption(f\"Feature Importances\").\\\n            set_properties(**{\"text-align\": \"center\"}).\\\n            background_gradient(subset = sel_cols,\n                                cmap = \"rocket\", \n                                axis=1\n                               )\n            )\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-08-03T12:42:11.406113Z","iopub.execute_input":"2024-08-03T12:42:11.407189Z","iopub.status.idle":"2024-08-03T12:42:40.940502Z","shell.execute_reply.started":"2024-08-03T12:42:11.407145Z","shell.execute_reply":"2024-08-03T12:42:40.939307Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CLOSURE**","metadata":{}},{"cell_type":"code","source":"def PostProcessPreds(sub_fl: pd.DataFrame, target: str = target):\n    \"This function post-processes the predictions using saved predictions and targets\"\n    \n    try:\n        sub_fl = sub_fl.set_index(\"id\")\n    except:\n        print(f\"---> Submission file index is intact\")\n\n    sub_fl.loc[3640058, target] = \"e\"\n    sub_fl.loc[sub_fl.index.isin([3600675, 4057201, 4729429, 4929268, 4985595]), target] = \"p\"\n    return sub_fl;","metadata":{"execution":{"iopub.status.busy":"2024-08-03T12:26:57.354538Z","iopub.execute_input":"2024-08-03T12:26:57.355055Z","iopub.status.idle":"2024-08-03T12:26:57.366398Z","shell.execute_reply.started":"2024-08-03T12:26:57.355012Z","shell.execute_reply":"2024-08-03T12:26:57.365159Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nprint(\"\\n\\n\")\nsub_fl[target] = np.where(test_preds >= cutoff, \"p\", \"e\")\nsub_fl = PostProcessPreds(sub_fl)\n\ntest_preds = \\\npd.DataFrame(test_preds,index = range(len(test)),\n             columns = [f\"{model_label}V{version_nb}_{model_group}\"],\n             dtype = np.float32,\n            )\n\nprint(\"\\n\\n\")\ndisplay(test_preds.head(10).style.set_caption(f\"Submission file predictions\"))\nprint(\"\\n\\n\")\ndisplay(sub_fl.head(10).style.set_caption(f\"Submission file labels\"))\nprint(\"\\n\\n\")\n\nOOF_Preds.index.name = \"id\"\nOOF_Preds.sort_index().reset_index().\\\nto_parquet(os.path.join(op_path, f'OOF_Preds_{model_label}V{version_nb}_{model_group}.parquet'))\n\ntest_preds.\\\nto_parquet(os.path.join(op_path, f'Mdl_Preds_{model_label}V{version_nb}_{model_group}.parquet'))\n\nsub_fl.\\\nto_parquet(os.path.join(op_path, f'Submission_{model_label}V{version_nb}_{model_group}.parquet'),\n           index= True\n          )\n\n%reset -f","metadata":{"execution":{"iopub.status.busy":"2024-08-03T12:27:01.515709Z","iopub.execute_input":"2024-08-03T12:27:01.517367Z","iopub.status.idle":"2024-08-03T12:27:02.029534Z","shell.execute_reply.started":"2024-08-03T12:27:01.517312Z","shell.execute_reply":"2024-08-03T12:27:02.027265Z"},"_kg_hide-input":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}